# Isomorfismo Modular en Inteligencia Artificial: Del Anillo $\mathbb{Z}/6\mathbb{Z}$ a NPUs Shared-Nothing

[![License: PolyForm Noncommercial](https://img.shields.io/badge/License-PolyForm_Noncommercial_1.0.0-red.svg)](LICENSE)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![Platform](https://img.shields.io/badge/Platform-Google_Colab_%7C_Linux-orange.svg)](Notebooks/VALIDACION_Z_6Z_IA.ipynb)
[![Status](https://img.shields.io/badge/Status-Validated_(p_value_<_0.05)-success.svg)]()
[![DOI](https://img.shields.io/badge/DOI-Zenodo-blue)](https://doi.org/10.5281/zenodo.17777464)

**Autor:** Jos√© Ignacio Peinador Sala  
**Contacto:** [joseignacio.peinador@gmail.com](mailto:joseignacio.peinador@gmail.com)  
**ORCID:** [0009-0008-1822-3452](https://orcid.org/0009-0008-1822-3452) 

---

## üìú Resumen Ejecutivo

Este repositorio presenta una nueva arquitectura para Inteligencia Artificial basada en el **Isomorfismo Modular**, dise√±ada para romper la dependencia de los chips monol√≠ticos de alta densidad .

Utilizando el anillo $\mathbb{Z}/6\mathbb{Z}$, demostramos que es posible descomponer redes neuronales profundas (MLPs y Transformers) en un "enjambre" de 6 sub-redes independientes (*Shared-Nothing*) . Esta topolog√≠a elimina la necesidad de coherencia de cach√© global y permite la construcci√≥n de NPUs mediante **chiplets de 28nm**, reduciendo los costes de fabricaci√≥n en **18x** frente a los nodos de 3nm .

![Diagrama Hex-NPU](Images/Hex_Ensemble.png)
*> Esquema de la NPU Hex-Ensemble: Distribuci√≥n pasiva de datos y procesamiento en 6 n√∫cleos aislados sin comunicaci√≥n cruzada.* 

---

## üöÄ Hito de Validaci√≥n: Robustez y Generalizaci√≥n Inversa

La arquitectura ha sido validada experimentalmente, demostrando que la "ceguera parcial" de los m√≥dulos act√∫a como un potente regularizador estructural.

| M√©trica | Resultado Validado | Referencia |
| :--- | :--- | :--- |
| **Precisi√≥n MNIST** | **97.03%** (vs 98.10% Monol√≠tico) | |
| **Transformer (Val)** | **94.75%** (Gap de Generalizaci√≥n Inverso) | |
| **Robustez Estad√≠stica** | **p-value = 0.0112** (Monte Carlo N=10) | *Notebook Analysis* |
| **Reducci√≥n de Coste** | **18x** (Arbitraje de Nodos 28nm vs 3nm) | |
| **Aislamiento** | **Total (Shared-Nothing)** | |

---

## üìÇ Estructura del Repositorio y üíª Reproducibilidad

* **`Paper/`**: Manuscrito cient√≠fico y demostraciones te√≥ricas.
    * `Isomorfismo_IA.pdf`: Art√≠culo completo detallando el operador *Stride-6* y el an√°lisis econ√≥mico. 
    * `Isomorfismo_IA.tex`: C√≥digo fuente LaTeX.
* **`Notebooks/`**: C√≥digo de validaci√≥n y experimentos.
    * [VALIDACION_Z_6Z_IA](https://colab.research.google.com/github/NachoPeinador/Isomorfismo-Modular-Z-6Z-en-Inteligencia-Artificial/blob/main/Notebooks/VALIDACION_Z_6Z_IA.ipynb) :
   
        - **Prueba de Isomorfismo Tensorial**: Verificaci√≥n matem√°tica de la descomposici√≥n $C = A \times B$ con error $< 10^{-5}$ .
        - **Hex-Ensemble en MNIST**: Entrenamiento de 6 workers ciegos con agregaci√≥n de votos .
        - **An√°lisis de Monte Carlo**: Test estad√≠stico que confirma la reducci√≥n del overfitting en Transformers Modulares.
* **`Images/`**: Diagramas de arquitectura y gr√°ficas de convergencia.

---

## ‚öôÔ∏è Innovaci√≥n T√©cnica

### 1. Operador de Proyecci√≥n Modular (Stride-6)
Formalizamos un operador $\mathcal{P}_r$ que proyecta tensores densos en 6 sub-espacios disjuntos bas√°ndose en congruencias modulares . Esto permite transformar operaciones matriciales globales en operaciones locales paralelizables.

### 2. Regularizaci√≥n por "Ceguera Parcial"
Descubrimos un fen√≥meno de **Gap de Generalizaci√≥n Inverso** . Al impedir que cada worker vea el 83% de los datos, el sistema se ve forzado a aprender caracter√≠sticas robustas, evitando la memorizaci√≥n del ruido (Overfitting) y superando a los modelos densos en datos de validaci√≥n .

### 3. Econom√≠a de Chiplets (Arbitraje de Nodos)
El dise√±o permite utilizar procesos de litograf√≠a maduros (28nm) para obtener rendimiento competitivo. Al evitar las ret√≠culas grandes y los defectos de los nodos de 3nm, el coste efectivo por transistor cae dr√°sticamente, democratizando el acceso a hardware de IA de alto rendimiento .

---

## ‚öñÔ∏è Licencia y Uso (Dual Licensing)

Este proyecto utiliza un modelo de **Licenciamiento Dual** alineado con los principios de la Ciencia Abierta sostenible .

### ‚úÖ Uso Acad√©mico y No Comercial
El c√≥digo fuente se distribuye bajo la licencia **PolyForm Noncommercial License 1.0.0**.
* **Permitido:** Investigaci√≥n, educaci√≥n y uso personal sin √°nimo de lucro .
* **Requisito:** Mantener la atribuci√≥n y este aviso de licencia.

### ‚õî Uso Comercial
Cualquier uso comercial (productos, servicios SaaS, consultor√≠a) est√° **estrictamente prohibido** sin acuerdo previo .

> üíº **Contacto para Licencias Comerciales:** [joseignacio.peinador@gmail.com](mailto:joseignacio.peinador@gmail.com) 

## ‚úçÔ∏è Citaci√≥n

Si utiliza esta arquitectura o el c√≥digo en su investigaci√≥n, por favor cite:

```bibtex
Peinador Sala, J. I. (2025). Modular Isomorphism in Artificial Intelligence: From the Ring Z/6Z to Shared-Nothing Architecture NPUs (Versi√≥n v1). Zenodo. https://doi.org/10.5281/zenodo.17777464
```

---

## üî¨ Ciencia Independiente y Abierta

> *"La perfecci√≥n no se alcanza cuando no hay nada m√°s que a√±adir, sino cuando no hay nada m√°s que quitar."* ‚Äî **Antoine de Saint-Exup√©ry**

Este trabajo demuestra que la inteligencia robusta no requiere la complejidad de un monolito interconectado, sino la elegancia de m√≥dulos eficientes. Realizado de manera independiente para democratizar el acceso al hardware de alto rendimiento.

